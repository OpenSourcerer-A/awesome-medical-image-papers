| 年份 | 题目 | 作者 | 摘要 | 中文摘要 | link |
| --- | --- | --- | --- | --- | --- |
| 2017 | Fine-Tuning Convolutional Neural Networks for Biomedical Image Analysis: Actively and Incrementally | Zongwei Zhou, Jae Shin, Lei Zhang, Suryakanth Gurudu, Michael Gotway, Jianming Liang | Intense interest in applying convolutional neural networks (CNNs) in biomedical image analysis is wide spread, but its success is impeded by the lack of large annotated datasets in biomedical imaging. Annotating biomedical images is not only tedious and time consuming, but also demanding of costly, specialty - oriented knowledge and skills, which are not easily accessible. To dramatically reduce annotation cost, this paper presents a novel method called AIFT (active, incremental fine-tuning) to naturally integrate active learning and transfer learning into a single framework. AIFT starts directly with a pre-trained CNN to seek "worthy" samples from the unannotated for annotation, and the (fine-tuned) CNN is further fine-tuned continuously by incorporating newly annotated samples in each iteration to enhance the CNN's performance incrementally. We have evaluated our method in three different biomedical imaging applications, demonstrating that the cost of annotation can be cut by at least half. This performance is attributed to the several advantages derived from the advanced active and incremental capability of our AIFT method. | 在生物医学图像分析中应用卷积神经网络（CNNs）引起了极大的兴趣，但由于生物医学成像领域缺乏大规模的标注数据集，其成功受到阻碍。标注生物医学图像不仅繁琐耗时，而且需要昂贵的专业知识和技能，这些知识和技能并不容易获取。为了显著降低标注成本，本文提出了一种名为AIFT（主动、递增微调）的新方法，将主动学习和迁移学习自然地整合到一个框架中。AIFT直接从经过预训练的CNN开始，从未标注的数据中寻找“有价值”的样本进行标注，并在每次迭代中不断将新标注样本纳入以逐步增强CNN的性能。我们在三个不同的生物医学图像应用中评估了我们的方法，证明标注成本可以至少减少一半。这一性能归因于我们AIFT方法先进的主动和递增能力所带来的几个优势。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Fine-Tuning_Convolutional_Neural_CVPR_2017_paper.pdf) |
| 2017 | LSTM Self-Supervision for Detailed Behavior Analysis | Biagio Brattoli, Uta Buchler, Anna-Sophia Wahl, Martin E. Schwab, Bjorn Ommer | Behavior analysis provides a crucial non-invasive and easily accessible diagnostic tool for biomedical research. A detailed analysis of posture changes during skilled motor tasks can reveal distinct functional deficits and their restoration during recovery. Our specific scenario is based on a neuroscientific study of rodents recovering from a large sensorimotor cortex stroke and skilled forelimb grasping is being recorded. Given large amounts of unlabeled videos that are recorded during such long-term studies, we seek an approach that captures fine-grained details of posture and its change during rehabilitation without costly manual supervision. Therefore, we utilize self-supervision to automatically learn accurate posture and behavior representations for analyzing motor function. Learning our model depends on the following fundamental elements: (i) limb detection based on a fully convolutional network is ini- tialized solely using motion information, (ii) a novel self- supervised training of LSTMs using only temporal permu- tation yields a detailed representation of behavior, and (iii) back-propagation of this sequence representation also im- proves the description of individual postures. We establish a novel test dataset with expert annotations for evaluation of fine-grained behavior analysis. Moreover, we demonstrate the generality of our approach by successfully applying it to self-supervised learning of human posture on two standard benchmark datasets. | 行为分析为生物医学研究提供了重要的非侵入性和易于获取的诊断工具。对技巧性运动任务中姿势变化的详细分析可以揭示明显的功能缺陷及其在康复期间的恢复情况。我们的具体场景基于对从大型感觉运动皮层中风中康复的啮齿动物进行的神经科学研究，并记录了技能前肢抓取。鉴于在此类长期研究中记录的大量未标记视频，我们寻求一种在康复过程中捕捉姿势及其变化微观细节的方法，而无需昂贵的手动监督。因此，我们利用自监督来自动学习准确的姿势和行为表示以分析运动功能。学习我们的模型取决于以下基本要素：（i）基于完全卷积网络的肢体检测仅使用运动信息进行初始化，（ii）仅使用时间排列的一种新颖的自监督训练LSTMs提供行为的详细表示，（iii）该序列表示的反向传播还改进了个体姿势的描述。我们建立了一个新颖的专家注释的测试数据集，用于评估微观行为分析。此外，我们通过成功将其应用于两个标准基准数据集上的人体姿势的自监督学习，展示了我们方法的普适性。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Brattoli_LSTM_Self-Supervision_for_CVPR_2017_paper.pdf) |
| 2017 | MDNet: A Semantically and Visually Interpretable Medical Image Diagnosis Network | Zizhao Zhang, Yuanpu Xie, Fuyong Xing, Mason McGough, Lin Yang | The inability to interpret the model prediction in semantically and visually meaningful ways is a well-known shortcoming of most existing computer-aided diagnosis methods. In this paper, we propose MDNet to establish a direct multimodal mapping between medical images and diagnostic reports that can read images, generate diagnostic reports, retrieve images by symptom descriptions, and visualize attention, to provide justifications of the network diagnosis process. MDNet includes an image model and a language model. The image model is proposed to enhance multi-scale feature ensembles and utilization efficiency. The language model, integrated with our improved attention mechanism, aims to read and explore discriminative image feature descriptions from reports to learn a direct mapping from sentence words to image pixels. The overall network is trained end-to-end by using our developed optimization strategy. Based on a pathology bladder cancer images and its diagnostic reports (BCIDR) dataset, we conduct sufficient experiments to demonstrate that MDNet outperforms comparative baselines. The proposed image model obtains state-of-the-art performance on two CIFAR datasets as well. | 大多数现有的计算机辅助诊断方法的一个众所周知的不足之处是无法以语义和视觉上有意义的方式解释模型预测。在本文中，我们提出了MDNet，建立了医学图像和诊断报告之间的直接多模态映射，可以读取图像，生成诊断报告，通过症状描述检索图像，并可视化注意力，以提供网络诊断过程的证明。MDNet包括一个图像模型和一个语言模型。图像模型旨在增强多尺度特征集合和利用效率。语言模型与我们改进的注意力机制结合，旨在从报告中阅读和探索区分性图像特征描述，以从句子单词直接映射到图像像素。整个网络使用我们开发的优化策略进行端到端训练。基于病理膀胱癌图像及其诊断报告（BCIDR）数据集，我们进行了足够的实验来证明MDNet优于比较基线。所提出的图像模型在两个CIFAR数据集上取得了最先进的性能。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_MDNet_A_Semantically_CVPR_2017_paper.pdf) |
| 2017 | Joint Sequence Learning and Cross-Modality Convolution for 3D Biomedical Segmentation | Kuan-Lun Tseng, Yen-Liang Lin, Winston Hsu, Chung-Yang Huang | Deep learning models such as convolutional neural network have been widely used in 3D biomedical segmentation and achieve state-of-the-art performance. However, most of them often adapt a single modality or stack multiple modalities as different input channels, which ignores the correlations among them. To leverage the multi-modalities, we propose a deep convolution encoder-decoder structure with fusion layers to incorporate different modalities of MRI data. In addition, we exploit convolutional LSTM (convLSTM) to model a sequence of 2D slices, and jointly learn the multi-modalities and convLSTM in an end-to-end manner. To avoid converging to the certain labels, we adopt a re-weighting scheme and two phase training to handle the label imbalance. Experimental results on BRATS-2015 show that our method outperforms state-of-the-art biomedical segmentation approaches. | 深度学习模型，如卷积神经网络，在3D生物医学分割中被广泛应用，并取得了最先进的性能。然而，大多数模型通常采用单一模态或堆叠多种模态作为不同的输入通道，忽略了它们之间的相关性。为了利用多模态，我们提出了一个深度卷积编码器-解码器结构，其中包括融合层，以整合不同MRI数据的模态。此外，我们利用卷积LSTM（convLSTM）来建模一系列2D切片，并以端到端的方式共同学习多模态和convLSTM。为避免收敛到特定标签，我们采用重新加权方案和两阶段训练来处理标签不平衡。在BRATS-2015上的实验结果表明，我们的方法优于最先进的生物医学分割方法。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Tseng_Joint_Sequence_Learning_CVPR_2017_paper.pdf) |
| 2017 | Seeing Into Darkness: Scotopic Visual Recognition | Bo Chen, Pietro Perona | Images are formed by counting how many photons traveling from a given set of directions hit an image sensor during a given time interval. When photons are few and far in between, the concept of `image' breaks down and it is best to consider directly the flow of photons. Computer vision in this regime, which we call `scotopic', is radically different from the classical image-based paradigm in that visual computations (classification, control, search) have to take place while the stream of photons is captured and decisions may be taken as soon as enough information is available. The scotopic regime is important for biomedical imaging, security, astronomy and many other fields. Here we develop a framework that allows a machine to classify objects with as few photons as possible, while maintaining the error rate below an acceptable threshold. A dynamic and asymptotically optimal speed-accuracy tradeoff is a key feature of this framework. We propose and study an algorithm to optimize the tradeoff of a convolutional network directly from lowlight images and evaluate on simulated images from standard datasets. Surprisingly, scotopic systems can achieve comparable classification performance as traditional vision systems while using less than 0.1% of the photons in a conventional image. In addition, we demonstrate that our algorithms work even when the illuminance of the environment is unknown and varying. Last, we outline a spiking neural network coupled with photon-counting sensors as a power-efficient hardware realization of scotopic algorithms.  | 图像是通过计算在给定时间间隔内从一组特定方向传播的光子击中图像传感器的数量来形成的。当光子稀少且相隔甚远时，`图像'的概念就会崩溃，最好直接考虑光子的流动。在这种我们称之为`暗视觉'的情况下，计算机视觉与传统基于图像的范式截然不同，因为在捕获光子流的同时必须进行视觉计算（分类、控制、搜索），并且可以在获得足够信息后立即做出决策。暗视觉的范围对生物医学成像、安全、天文学和许多其他领域非常重要。在这里，我们开发了一个框架，允许机器在尽可能少的光子的情况下对对象进行分类，同时保持错误率在可接受的阈值以下。动态和渐近最优的速度-准确性权衡是这一框架的关键特点。我们提出并研究了一种算法，直接从低光图像优化卷积网络的权衡，并在标准数据集的模拟图像上进行评估。令人惊讶的是，暗视觉系统可以在使用传统图像的不到0.1%的光子的情况下实现可比较的分类性能。此外，我们证明我们的算法即使在环境的照度未知且变化时也能正常工作。最后，我们概述了一个脉冲神经网络，配合光子计数传感器，作为暗视觉算法的功耗高效硬件实现。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_Seeing_Into_Darkness_CVPR_2017_paper.pdf) |
| 2017 | The Incremental Multiresolution Matrix Factorization Algorithm | Vamsi K. Ithapu, Risi Kondor, Sterling C. Johnson, Vikas Singh | Multiresolution analysis and matrix factorization are foundational tools in computer vision. In this work, we study the interface between these two distinct topics and obtain techniques to uncover hierarchical block structure in symmetric matrices -- an important aspect in the success of many vision problems. Our new algorithm, the incremental multiresolution matrix factorization, uncovers such structure one feature at a time, and hence scales well to large matrices. We describe how this multiscale analysis goes much farther than what a direct "global" factorization of the data can identify.  We evaluate the efficacy of the resulting factorizations for relative leveraging within regression tasks using medical imaging data.   We also use the factorization on representations learned by popular deep networks,  providing evidence of their ability to infer semantic relationships even when they are not explicitly trained to do so. We show that this algorithm can be used as an exploratory tool to improve the network architecture, and within numerous other settings in vision.  | 多分辨率分析和矩阵分解是计算机视觉中的基础工具。在这项工作中，我们研究了这两个不同主题之间的接口，并获得了一些技术，可以揭示对称矩阵中的分层块结构——这是许多视觉问题成功的重要方面。我们的新算法，增量多分辨率矩阵分解，逐个特征地揭示这种结构，因此可以很好地扩展到大矩阵。我们描述了这种多尺度分析的效果远远超过直接对数据进行“全局”分解所能识别的范围。我们评估了所得到的分解在医学影像数据中相对杠杆效果的有效性。我们还将分解应用于流行的深度网络学习的表示，为它们能够推断语义关系提供了证据，即使它们并未明确训练为这样做。我们展示了这个算法可以作为改进网络架构的探索工具，并在视觉中的许多其他环境中使用。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Ithapu_The_Incremental_Multiresolution_CVPR_2017_paper.pdf) |
| 2017 | Riemannian Nonlinear Mixed Effects Models: Analyzing Longitudinal Deformations in Neuroimaging | Hyunwoo J. Kim, Nagesh Adluru, Heemanshu Suri, Baba C. Vemuri, Sterling C. Johnson, Vikas Singh | Statistical machine learning models that operate on manifold-valued data are being extensively studied in vision, motivated by applications in activity recognition, feature tracking and medical imaging. While non-parametric methods have been relatively well studied in the literature, efficient formulations for parametric models (which may offer benefits in small sample size regimes) have only emerged recently. So far, manifold-valued regression models (such as geodesic regression) are restricted to the analysis of cross-sectional data, i.e., the so-called "fixed effects" in statistics. But in most "longitudinal analysis" (e.g., when a participant provides multiple measurements, over time) the application of fixed effects models is problematic. In an effort to answer this need, this paper generalizes non-linear mixed effects model to the regime where the response variable is manifold-valued, i.e., f:R^d -> M. We derive the underlying model and estimation schemes and demonstrate the immediate benefits such a model can provide --- both for group level and individual level analysis --- on longitudinal brain imaging data. The direct consequence of our results is that longitudinal analysis of manifold-valued measurements (especially, the symmetric positive definite manifold) can be conducted in a computationally tractable manner.   | 在视觉领域，对操作于流形值数据的统计机器学习模型进行了广泛研究，这是由于在活动识别、特征跟踪和医学成像等应用中的动机。虽然非参数方法在文献中已经得到了相对充分的研究，但对于参数模型的高效表达（在小样本量情况下可能会带来好处）仅在最近才出现。到目前为止，流形值回归模型（如测地线回归）仅限于对横断面数据的分析，即统计学中所谓的“固定效应”。但在大多数“纵向分析”（例如当参与者随时间提供多次测量时），固定效应模型的应用存在问题。为了满足这一需求，本文将非线性混合效应模型推广到响应变量为流形值的情形，即f:R^d -> M。我们推导了基本模型和估计方案，并展示了这种模型可以提供的直接益处---无论是在群体水平还是个体水平上的分析---在纵向脑成像数据上。我们的结果的直接后果是，流形值测量的纵向分析（特别是对称正定流形）可以以可计算的方式进行。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Kim_Riemannian_Nonlinear_Mixed_CVPR_2017_paper.pdf) |
| 2017 | Designing Illuminant Spectral Power Distributions for Surface Classification | Henryk Blasinski, Joyce Farrell, Brian Wandell | There are many scientific, medical and industrial imaging applications where users have full control of the scene illumination and color reproduction is not the primary objective For example, it is possible to co-design sensors and spectral illumination in order to classify and detect changes in biological tissues, organic and inorganic materials, and object surface properties.  In this paper, we propose two different approaches to illuminant spectrum selection for surface classification. In the supervised framework we formulate a biconvex optimization problem where we alternate between optimizing support vector classifier weights and optimal illuminants. We also describe a sparse Principal Component Analysis (PCA) dimensionality reduction approach that can be used with unlabeled data. We efficiently solve the non-convex PCA problem using a convex relaxation and Alternating Direction Method of Multipliers (ADMM). We compare the classification accuracy of a monochrome imaging sensor with optimized illuminants to the classification accuracy of conventional RGB cameras with natural broadband illumination. | 在许多科学、医学和工业成像应用中，用户可以完全控制场景照明，而颜色再现并非主要目标。例如，可以共同设计传感器和光谱照明，以便对生物组织、有机和无机材料以及对象表面特性进行分类和检测。在本文中，我们提出了两种不同的表面分类的光源谱选择方法。在监督框架中，我们制定了一个双凸优化问题，其中我们在优化支持向量分类器权重和最佳照明之间交替。我们还描述了一种稀疏主成分分析（PCA）降维方法，可用于未标记的数据。我们通过凸松弛和交替方向乘法器（ADMM）有效地解决了非凸PCA问题。我们将优化照明的单色成像传感器的分类准确性与传统RGB相机在自然宽带照明下的分类准确性进行了比较。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Blasinski_Designing_Illuminant_Spectral_CVPR_2017_paper.pdf) |
| 2017 | A Message Passing Algorithm for the Minimum Cost Multicut Problem | Paul Swoboda, Bjoern Andres | We propose a dual decomposition and linear program relaxation of the NP-hard minimum cost multicut problem. Unlike other polyhedral relaxations of the multicut polytope, it is amenable to efficient optimization by message passing. Like other polyhedral relaxations, it can be tightened efficiently by cutting planes. We define an algorithm that alternates between message passing and efficient separation of cycle- and odd-wheel inequalities. This algorithm is more efficient than state-of-the-art algorithms based on linear programming, including algorithms written in the framework of leading commercial software, as we show in experiments with large instances of the problem from applications in computer vision, biomedical image analysis and data mining. | 我们提出了一个NP-hard最小成本多切问题的双重分解和线性规划松弛。与其他多切多面体的多面体松弛不同，它可以通过消息传递进行高效优化。与其他多面体松弛一样，它可以通过切平面有效地加强。我们定义了一个算法，该算法在消息传递和循环和奇数轮不等式的有效分离之间交替。正如我们在计算机视觉、生物医学图像分析和数据挖掘应用中的大规模问题实验中展示的那样，这个算法比基于线性规划的最先进算法更有效，包括在领先商业软件框架中编写的算法。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Swoboda_A_Message_Passing_CVPR_2017_paper.pdf) |
| 2017 | Efficient Optimization for Hierarchically-structured Interacting Segments (HINTS) | Hossam Isack, Olga Veksler, Ipek Oguz, Milan Sonka, Yuri Boykov | We propose an effective optimization algorithm for a general hierarchical segmentation model with geometric interactions between segments. Any given tree can specify a partial order over object labels defining a hierarchy. It is well-established that segment interactions, such as inclusion/exclusion and margin constraints, make the model significantly more discriminant. However, existing optimization methods do not allow full use of such models. Generic a-expansion results in weak local minima, while common binary multi-layered formulations lead to non-submodularity, complex high-order potentials, or polar domain unwrapping and shape biases. In practice, applying these methods to arbitrary trees does not work except for simple cases. Our main contribution is an optimization method for the Hierarchically-structured Interacting Segments (HINTS) model with arbitrary trees. Our Path-Moves algorithm is based on multi-label MRF formulation and can be seen as a combination of well-known a-expansion and Ishikawa techniques. We show state-of-the-art biomedical segmentation for many diverse examples of complex trees. | 我们提出了一种针对具有几何相互作用的一般分层分割模型的有效优化算法。任何给定的树都可以指定一个对象标签的部分顺序，定义一个层次结构。众所周知，段之间的相互作用，如包含/排除和边界约束，使模型显著更具辨别性。然而，现有的优化方法并未充分利用这样的模型。通用的a扩展结果会导致弱局部最小值，而常见的二进制多层次公式会导致非次模性，复杂的高阶潜力，或极地域域展开和形状偏差。在实践中，将这些方法应用于任意树的情况除了简单情况之外并不奏效。我们的主要贡献是一种针对具有任意树的分层结构相互作用段（HINTS）模型的优化方法。我们的Path-Moves算法基于多标签MRF公式，并可以看作是著名的a扩展和石川技术的结合。我们展示了针对许多复杂树的多样化实例的最先进的生物医学分割。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Isack_Efficient_Optimization_for_CVPR_2017_paper.pdf) |
| 2017 | Video Acceleration Magnification | Yichao Zhang, Silvia L. Pintea, Jan C. van Gemert | The ability to amplify or reduce subtle image changes over time is useful in contexts such as video editing, medical video analysis, product quality control and sports. In these contexts there is often large motion present which severely distorts current video amplification methods that magnify change linearly. In this work we propose a method to cope with large motions while still magnifying small changes. We make the following two observations: i) large motions are linear on the temporal scale of the small changes; ii) small changes deviate from this linearity. We ignore linear motion and propose to magnify acceleration. Our method is pure Eulerian and does not require any optical flow, temporal alignment or region annotations. We link temporal second-order derivative filtering to spatial acceleration magnification. We apply our method to moving objects where we show motion magnification and color magnification. We provide quantitative as well as qualitative evidence for our method while comparing to the state-of-the-art. | 在视频编辑、医学视频分析、产品质量控制和体育等情境中，放大或减少随时间发生的微小图像变化的能力是很有用的。在这些情境中，通常存在大幅度的运动，这严重扭曲了目前线性放大变化的视频放大方法。在这项工作中，我们提出了一种方法来处理大幅度的运动，同时放大微小变化。我们得出以下两个观察结果：i) 大幅度的运动在微小变化的时间尺度上是线性的；ii) 微小变化与这种线性偏离。我们忽略线性运动，提出放大加速度的方法。我们的方法是纯欧拉方法，不需要任何光流、时间对齐或区域注释。我们将时间二阶导数滤波与空间加速度放大联系起来。我们将我们的方法应用于移动物体，展示了运动放大和颜色放大。我们提供了与最先进方法进行比较的定量和定性证据。 | [link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Video_Acceleration_Magnification_CVPR_2017_paper.pdf) |
