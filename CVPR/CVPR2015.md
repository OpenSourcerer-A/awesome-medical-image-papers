| 年份 | 题目 | 作者 | 摘要 | 中文摘要 | link |
| --- | --- | --- | --- | --- | --- |
| 2015 | Fine-Grained Histopathological Image Analysis via Robust Segmentation and Large-Scale Retrieval | Xiaofan Zhang, Hai Su, Lin Yang, Shaoting Zhang | Computer-aided diagnosis of medical images requires thorough analysis of image details. For example, examining all cells enables fine-grained categorization of histopathological images. Traditional computational methods may have efficiency issues when performing such detailed analysis. In this paper, we propose a robust and scalable solution to achieve this. Specifically, a robust segmentation method is developed to delineate region-of-interests (e.g., cells) accurately, using hierarchical voting and repulsive active contour. A hashing-based large-scale retrieval approach is also designed to examine and classify them by comparing with a massive training database. We evaluate this proposed framework on a challenging and important clinical use case, i.e., differentiation of two types of lung cancers (the adenocarcinoma and the squamous carcinoma), using thousands of histopathological images extracted from hundreds of patients. Our method has achieved promising performance, i.e., 87.3% accuracy and 1.68 seconds by searching among half-million cells. | 医学图像的计算机辅助诊断需要对图像细节进行彻底分析。例如，检查所有细胞可以对组织病理学图像进行细粒度分类。传统的计算方法在执行这种详细分析时可能存在效率问题。在本文中，我们提出了一个强大且可扩展的解决方案来实现这一目标。具体而言，我们开发了一种强大的分割方法，利用层次投票和斥力主动轮廓来准确勾勒感兴趣区域(例如，细胞)。我们还设计了一种基于哈希的大规模检索方法，通过与庞大的训练数据库进行比较来检查和分类这些细胞。我们在一个具有挑战性和重要的临床用例上评估了这个提出的框架，即区分两种肺癌类型(腺癌和鳞状细胞癌)，使用了来自数百名患者的数千张组织病理学图像。我们的方法取得了令人满意的表现，即87.3%的准确率，并在搜索50万个细胞中只需1.68秒。 | [link](https://openaccess.thecvf.com/content_cvpr_2015/papers/Zhang_Fine-Grained_Histopathological_Image_2015_CVPR_paper.pdf) |
| 2015 | Deep Sparse Representation for Robust Image Registration | Yeqing Li, Chen Chen, Fei Yang, Junzhou Huang | The definition of the similarity measure is an essential component in image registration. In this paper, we propose a novel similarity measure for registration of two or more images. The proposed method is motivated by that the optimally registered images can be deeply sparsified in the gradient domain and frequency domain, with the separation of a sparse tensor of errors. One of the key advantages of the proposed similarity measure is its robustness to severe intensity distortions, which widely exist on medical images, remotely sensed images and natural photos due to the difference of acquisition modalities or illumination conditions. Two efficient algorithms are proposed to solve the batch image registration and pair registration problems in a unified framework. We validate our method on extensive challenging datasets. The experimental results demonstrate the robustness, accuracy and efficiency of our method over 9 traditional and state-of-the-art algorithms on synthetic images and a wide range of real-world applications. | 图像配准中相似性度量的定义是一个重要组成部分。本文提出了一种新颖的用于两个或多个图像配准的相似性度量方法。所提出的方法受到了优化配准图像可以在梯度域和频率域中进行深度稀疏化，通过稀疏误差张量的分离的启发。所提出的相似性度量的一个关键优势是其对严重强度失真的鲁棒性，这种失真广泛存在于医学图像、遥感图像和自然照片中，这是由于获取模式或光照条件的不同。提出了两种高效的算法，以统一的框架解决批量图像配准和成对配准问题。我们在广泛具有挑战性的数据集上验证了我们的方法。实验结果表明，我们的方法在合成图像和各种真实应用中比9种传统和最先进的算法具有更强的鲁棒性、准确性和效率。 | [link](https://openaccess.thecvf.com/content_cvpr_2015/papers/Li_Deep_Sparse_Representation_2015_CVPR_paper.pdf) |
| 2015 | Transformation-Invariant Convolutional Jungles | Dmitry Laptev, Joachim M. Buhmann | Many Computer Vision problems arise from information processing of data sources with nuisance variances like scale, orientation, contrast, perspective foreshortening or - in medical imaging - staining and local warping. In most cases these variances can be stated a priori and can be used to improve the generalization of recognition algorithms. We propose a novel supervised feature learning approach, which efficiently extracts information from these constraints to produce interpretable, transformation-invariant features. The proposed method can incorporate a large class of transformations, e.g., shifts, rotations, change of scale, morphological operations, non-linear distortions, photometric transformations, etc. These features boost the discrimination power of a novel image classification and segmentation method, which we call Transformation-Invariant Convolutional Jungles (TICJ). We test the algorithm on two benchmarks in face recognition and medical imaging, where it achieves state of the art results, while being computationally significantly more efficient than Deep Neural Networks. | 许多计算机视觉问题源于对具有烦扰变量的数据源的信息处理，如尺度、方向、对比度、透视缩短或在医学影像中的染色和局部扭曲。在大多数情况下，这些变异性可以事先陈述，并可用于改进识别算法的泛化能力。我们提出了一种新颖的监督特征学习方法，有效地从这些约束中提取信息，以产生可解释的、具有变换不变性的特征。所提出的方法可以包含大量的变换类别，如平移、旋转、尺度变化、形态学操作、非线性扭曲、光度变换等。这些特征提升了一种新颖的图像分类和分割方法的判别力，我们称之为变换不变卷积丛林（TICJ）。我们在人脸识别和医学影像的两个基准测试中测试了该算法，在这些测试中它取得了最先进的结果，同时在计算上比深度神经网络显著更有效。 | [link](https://openaccess.thecvf.com/content_cvpr_2015/papers/Laptev_Transformation-Invariant_Convolutional_Jungles_2015_CVPR_paper.pdf) |
| 2015 | Total Variation Regularization of Shape Signals | Maximilian Baust, Laurent Demaret, Martin Storath, Nassir Navab, Andreas Weinmann | This paper introduces the concept of shape signals, i.e., series of shapes which have a natural temporal or spatial ordering, as well as a variational formulation for the regularization of these signals. The proposed formulation can be seen as the shape-valued generalization of the Rudin-Osher-Fatemi (ROF) functional for intensity images. We derive a variant of the classical finite-dimensional representation of Kendall, but our framework is generic in the sense that it can be combined with any shape space. This representation allows for the explicit computation of geodesics and thus facilitates the efficient numerical treatment of the variational formulation by means of the cyclic proximal point algorithm. Similar to the ROF-functional, we demonstrate experimentally that l_1-type penalties both for data fidelity term and regularizer perform best in regularizing shape signals. Finally, we show applications of our method to shape signals obtained from synthetic, photometric, and medical data sets. | 本文介绍了形状信号的概念，即具有自然时间或空间排序的一系列形状，以及对这些信号进行正则化的变分形式。所提出的公式可以看作是对强度图像的Rudin-Osher-Fatemi（ROF）功能的形状值泛化。我们推导了Kendall经典有限维表示的一个变种，但我们的框架是通用的，因为它可以与任何形状空间结合。这种表示允许明确计算测地线，从而通过循环近端点算法有效地处理变分公式的数值处理。与ROF功能类似，我们通过实验证明，l_1类型的数据保真度项和正则化器在正则化形状信号方面表现最佳。最后，我们展示了我们的方法应用于从合成、光度和医学数据集获得的形状信号。 | [link](https://openaccess.thecvf.com/content_cvpr_2015/papers/Baust_Total_Variation_Regularization_2015_CVPR_paper.pdf) |
| 2015 | Interleaved Text/Image Deep Mining on a Very Large-Scale Radiology Database | Hoo-Chang Shin, Le Lu, Lauren Kim, Ari Seff, Jianhua Yao, Ronald M. Summers | Despite tremendous progress in computer vision, effective learning on very large-scale (>100K patients) medical image databases has been vastly hindered. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's picture archiving and communication system. Instead of using full 3D medical volumes, we focus on a collection of representative ~216K 2D key images/slices (selected by clinicians for diagnostic reference) with text-driven scalar and vector labels. Our system interleaves between unsupervised learning (e.g., latent Dirichlet allocation, recurrent neural net language models) on document- and sentence-level texts to generate semantic labels and supervised learning via deep convolutional neural networks (CNNs) to map from images to label spaces. Disease-related key words can be predicted for radiology images in a retrieval manner. We have demonstrated promising quantitative and qualitative results. The large-scale datasets of extracted key images and their categorization, embedded vector labels and sentence descriptions can be harnessed to alleviate the deep learning "data-hungry" obstacle in the medical domain. | 尽管计算机视觉取得了巨大进展，但在非常大规模（>100K 患者）医学图像数据库上进行有效学习仍然受到极大阻碍。我们提出了一种交错文本/图像深度学习系统，用于从国家研究医院的影像存档与通信系统中提取和挖掘放射学图像和报告的语义交互。我们不使用完整的3D 医学体积，而是专注于一组代表性的约216K 2D 关键图像/切片（由临床医生选择用于诊断参考），带有文本驱动的标量和向量标签。我们的系统在文档和句子级别文本上交替进行无监督学习（例如，潜在狄利克雷分配，递归神经网络语言模型）以生成语义标签，并通过深度卷积神经网络（CNN）进行监督学习，将图像映射到标签空间。可以通过检索方式预测放射学图像的与疾病相关的关键词。我们展示了令人满意的定量和定性结果。提取的关键图像和其分类、嵌入式向量标签和句子描述的大规模数据集可以用来克服医学领域中深度学习“数据饥渴”障碍。 | [link](https://openaccess.thecvf.com/content_cvpr_2015/papers/Shin_Interleaved_TextImage_Deep_2015_CVPR_paper.pdf) |
| 2015 | Mapping Visual Features to Semantic Profiles for Retrieval in Medical Imaging | Johannes Hofmanninger, Georg Langs | Content based image retrieval is highly relevant in medical imaging, since it makes vast amounts of imaging data accessible for comparison during diagnosis. Finding image similarity measures that reflect diagnostically relevant relationships is challenging, since the overall appearance variability is high compared to often subtle signatures of diseases. To learn models that capture the relationship between semantic clinical information and image elements at scale, we have to rely on data generated during clinical routine (images and radiology reports), since expert annotation is prohibitively costly. Here we show that re-mapping visual features extracted from medical imaging data based on weak labels that can be found in corresponding radiology reports creates descriptions of local image content capturing clinically relevant information. We show that these semantic profiles enable higher recall and precision during retrieval compared to visual features, and that we can even map semantic terms describing clinical findings from radiology reports to localized image volume areas. | 基于内容的图像检索在医学影像领域具有高度相关性，因为它使大量的影像数据在诊断过程中可以进行比较。寻找能够反映诊断相关关系的图像相似性度量是具有挑战性的，因为总体外观的变异性相对较高，而疾病的特征往往是微妙的。为了学习能够在规模上捕捉语义临床信息与图像元素之间关系的模型，我们必须依赖于在临床常规过程中生成的数据（影像和放射学报告），因为专家注释成本过高。在这里，我们展示了基于可以在相应的放射学报告中找到的弱标签重新映射从医学影像数据中提取的视觉特征，可以创建捕捉临床相关信息的局部图像内容描述。我们发现，这些语义描述能够在检索过程中实现更高的召回率和精度，甚至可以将描述放射学报告中描述临床发现的语义术语映射到局部图像体积区域。 | [link](https://openaccess.thecvf.com/content_cvpr_2015/papers/Hofmanninger_Mapping_Visual_Features_2015_CVPR_paper.pdf) |
