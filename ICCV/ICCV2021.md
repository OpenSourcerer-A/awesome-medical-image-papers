| 年份 | 题目 | 作者 | 摘要 | 中文摘要 | link |
| --- | --- | --- | --- | --- | --- |
| 2021 | Graph-BAS3Net: Boundary-Aware Semi-Supervised Segmentation Network With Bilateral Graph Convolution | Huimin Huang, Lanfen Lin, Yue Zhang, Yingying Xu, Jing Zheng, XiongWei Mao, Xiaohan Qian, Zhiyi Peng, Jianying Zhou, Yen-Wei Chen, Ruofeng Tong | Semi-supervised learning (SSL) algorithms have attracted much attentions in medical image segmentation by leveraging unlabeled data, which challenge in acquiring massive pixel-wise annotated samples. However, most of the existing SSLs neglected the geometric shape constraint in object, leading to unsatisfactory boundary and non-smooth of object. In this paper, we propose a novel boundary-aware semi-supervised medical image segmentation network, named Graph-BAS3Net, which incorporates the boundary information and learns duality constraints between semantics and geometrics in the graph domain. Specifically, the proposed method consists of two components: a multi-task learning framework BAS3Net and a graph-based cross-task module BGCM. The BAS3Net improves the existing GAN-based SSL by adding a boundary detection task, which encodes richer features of object shape and surface. Moreover, the BGCM further explores the co-occurrence relations between the semantics segmentation and boundary detection task, so that the network learns stronger semantic and geometric correspondences from both labeled and unlabeled data. Experimental results on the LiTS dataset and COVID-19 dataset confirm that our proposed Graph-BAS3 Net outperforms the state-of-the-art methods in semi-supervised segmentation task. | 半监督学习（SSL）算法通过利用未标记数据在医学图像分割领域引起了广泛关注，挑战在获取大量像素级注释样本方面存在困难。然而，大多数现有的SSL方法忽略了对象的几何形状约束，导致边界和对象的不光滑。本文提出了一种新颖的边界感知半监督医学图像分割网络，命名为Graph-BAS3Net，该网络融合了边界信息，并在图领域学习了语义和几何之间的对偶约束。具体而言，所提出的方法包括两个组成部分：多任务学习框架BAS3Net和基于图的跨任务模块BGCM。BAS3Net通过添加边界检测任务改进了现有的基于GAN的SSL方法，从而编码了对象形状和表面的更丰富特征。此外，BGCM进一步探索了语义分割和边界检测任务之间的共现关系，使网络能够从标记和未标记数据中学习更强的语义和几何对应关系。在LiTS数据集和COVID-19数据集上的实验结果证实，我们提出的Graph-BAS3Net在半监督分割任务中胜过了现有的最先进方法。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Graph-BAS3Net_Boundary-Aware_Semi-Supervised_Segmentation_Network_With_Bilateral_Graph_Convolution_ICCV_2021_paper.pdf) |
| 2021 | Generative Adversarial Registration for Improved Conditional Deformable Templates | Neel Dey, Mengwei Ren, Adrian V. Dalca, Guido Gerig | Deformable templates are essential to large-scale medical image registration, segmentation, and population analysis. Current conventional and deep network-based methods for template construction use only regularized registration objectives and often yield templates with blurry and/or anatomically implausible appearance, confounding downstream biomedical interpretation. We reformulate deformable registration and conditional template estimation as an adversarial game wherein we encourage realism in the moved templates with a generative adversarial registration framework conditioned on flexible image covariates. The resulting templates exhibit significant gain in specificity to attributes such as age and disease, better fit underlying group-wise spatiotemporal trends, and achieve improved sharpness and centrality. These improvements enable more accurate population modeling with diverse covariates for standardized downstream analyses and easier anatomical delineation for structures of interest. | 可变形模板对于大规模医学图像配准、分割和人群分析至关重要。目前传统和基于深度网络的模板构建方法仅使用规范化的配准目标，并且通常会产生模糊和/或解剖学上不合理的外观的模板，使得下游生物医学解释变得混淆。我们将可变形配准和条件模板估计重新表述为对抗性游戏，在其中我们通过基于灵活图像协变量的生成对抗式配准框架来鼓励移动模板的真实性。结果模板在特征（如年龄和疾病）的特异性方面表现出显著增益，更好地符合基础群体式时空趋势，并实现了改进的清晰度和中心性。这些改进使得使用多样化协变量进行更准确的人群建模，用于标准化下游分析，并为感兴趣结构的解剖划分更加容易。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Dey_Generative_Adversarial_Registration_for_Improved_Conditional_Deformable_Templates_ICCV_2021_paper.pdf) |
| 2021 | Large-Scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification | Zhuoning Yuan, Yan Yan, Milan Sonka, Tianbao Yang | Deep AUC Maximization (DAM) is a new paradigm for learning a deep neural network by maximizing the AUC score of the model on a dataset. Most previous works of AUC maximization focus on the perspective of optimization by designing efficient stochastic algorithms, and studies on generalization performance of large-scale DAM on difficult tasks are missing. In this work, we aim to make DAM more practical for interesting real-world applications (e.g., medical image classification). First, we propose a new margin-based min-max surrogate loss function for the AUC score (named as the AUC min-max-margin loss or simply AUC margin loss for short). It is more robust than the commonly used AUC square loss, while enjoying the same advantage in terms of large-scale stochastic optimization. Second, we conduct extensive empirical studies of our DAM method on four difficult medical image classification tasks, namely (i) classification of chest x-ray images for identifying many threatening diseases, (ii) classification of images of skin lesions for identifying melanoma, (iii) classification of mammogram for breast cancer screening, and (iv) classification of microscopic images for identifying tumor tissue. Our studies demonstrate that the proposed DAM method improves the performance of optimizing cross-entropy loss by a large margin, and also achieves better performance than optimizing the existing AUC square loss on these medical image classification tasks. Specifically, our DAM method has achieved the 1st place on Stanford CheXpert competition on Aug. 31, 2020. To the best of our knowledge, this is the first work that makes DAM succeed on large-scale medical image datasets. We also conduct extensive ablation studies to demonstrate the advantages of the new AUC margin loss over the AUC square loss on benchmark datasets. The proposed method is implemented in our open-sourced library LibAUC (www.libauc.org) whose github address is https://github.com/Optimization-AI/LibAUC. | Deep AUC Maximization (DAM)是一种通过最大化数据集上模型的AUC得分来学习深度神经网络的新范式。大多数以前的AUC最大化工作侧重于通过设计高效的随机算法来优化，而缺乏对难度任务上大规模DAM的泛化性能的研究。在这项工作中，我们旨在使DAM对有趣的现实世界应用（例如医学图像分类）更加实用。首先，我们提出了一种基于边缘的最小最大替代损失函数用于AUC得分（简称AUC min-max-margin损失或简称AUC margin损失）。它比常用的AUC平方损失更加鲁棒，同时在大规模随机优化方面具有相同的优势。其次，我们在四项困难的医学图像分类任务上对我们的DAM方法进行了广泛的实证研究，即（i）用于识别多种威胁性疾病的胸部X射线图像分类，（ii）用于鉴别黑色素瘤的皮肤病变图像分类，（iii）用于乳腺癌筛查的乳房X线摄影分类，以及（iv）用于鉴别肿瘤组织的显微镜图像分类。我们的研究表明，提出的DAM方法在优化交叉熵损失的性能方面取得了很大进步，并且在这些医学图像分类任务上的表现也优于优化现有的AUC平方损失。具体来说，我们的DAM方法在2020年8月31日赢得了斯坦福CheXpert比赛的第一名。据我们所知，这是第一次使DAM在大规模医学图像数据集上取得成功。我们还进行了广泛的消融研究，以展示新的AUC margin损失在基准数据集上优于AUC平方损失的优势。提出的方法已在我们的开源库LibAUC（www.libauc.org）中实现，其github地址为https://github.com/Optimization-AI/LibAUC。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Yuan_Large-Scale_Robust_Deep_AUC_Maximization_A_New_Surrogate_Loss_and_ICCV_2021_paper.pdf) |
| 2021 | Semantic Aware Data Augmentation for Cell Nuclei Microscopical Images With Artificial Neural Networks | Alireza Naghizadeh, Hongye Xu, Mohab Mohamed, Dimitris N. Metaxas, Dongfang Liu | There exists many powerful architectures for object detection and semantic segmentation of both biomedical and natural images. However, a difficulty arises in the ability to create training datasets that are large and well-varied. The importance of this subject is nested in the amount of training data that artificial neural networks need to accurately identify and segment objects in images and the infeasibility of acquiring a sufficient dataset within the biomedical field. This paper introduces a new data augmentation method that generates artificial cell nuclei microscopical images along with their correct semantic segmentation labels. Data augmentation provides a step toward accessing higher generalization capabilities of artificial neural networks. An initial set of segmentation objects is used with Greedy AutoAugment to find the strongest performing augmentation policies. The found policies and the initial set of segmentation objects are then used in the creation of the final artificial images. When comparing the state-of-the-art data augmentation methods with the proposed method, the proposed method is shown to consistently outperform current solutions in the generation of nuclei microscopical images. | 目前存在许多用于生物医学和自然图像对象检测和语义分割的强大架构。然而，一个困难在于创建大型且多样化的训练数据集的能力。这个主题的重要性在于人工神经网络需要准确识别和分割图像中的对象所需的训练数据量，以及在生物医学领域获取足够数据集的不可行性。本文介绍了一种新的数据增强方法，该方法生成人工细胞核显微图像以及它们的正确语义分割标签。数据增强是向人工神经网络的更高泛化能力迈出的一步。使用贪婪自动增强来找到性能最强的增强策略，并将找到的策略和初始分割对象集用于创建最终的人工图像。将提出的方法与最先进的数据增强方法进行比较，结果表明提出的方法在生成细胞核显微图像方面始终优于当前解决方案。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Naghizadeh_Semantic_Aware_Data_Augmentation_for_Cell_Nuclei_Microscopical_Images_With_ICCV_2021_paper.pdf) |
| 2021 | Recurrent Mask Refinement for Few-Shot Medical Image Segmentation | Hao Tang, Xingwei Liu, Shanlin Sun, Xiangyi Yan, Xiaohui Xie | Although having achieved great success in medical image segmentation, deep convolutional neural networks usually require a large dataset with manual annotations for training and are difficult to generalize to unseen classes. Few-shot learning has the potential to address these challenges by learning new classes from only a few labeled examples. In this work, we propose a new framework for few-shot medical image segmentation based on prototypical networks. Our innovation lies in the design of two key modules: 1) a context relation encoder (CRE) that uses correlation to capture local relation features between foreground and background regions; and 2) a recurrent mask refinement module that repeatedly uses the CRE and a prototypical network to recapture the change of context relationship and refine the segmentation mask iteratively. Experiments on two abdomen CT datasets and an abdomen MRI dataset show the proposed method obtains substantial improvement over the state-of-the-art methods by an average of 16.32%, 8.45% and 6.24% in terms of DSC, respectively. Code is publicly available. | 尽管深度卷积神经网络在医学图像分割方面取得了巨大成功，但通常需要一个具有手动注释的大型数据集进行训练，并且很难推广到未见过的类别。少样本学习有潜力通过仅学习少量标记示例来解决这些挑战。在这项工作中，我们提出了一个基于原型网络的少样本医学图像分割的新框架。我们的创新在于设计了两个关键模块：1）上下文关系编码器（CRE），它使用相关性来捕获前景和背景区域之间的局部关系特征；2）一个重复使用CRE和原型网络来重新捕捉上下文关系变化并迭代地优化分割掩模的重复掩模细化模块。在两个腹部CT数据集和一个腹部MRI数据集上的实验表明，所提出的方法在DSC方面分别平均提高了16.32％，8.45％和6.24％，显著超越了最先进的方法。代码已公开提供。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Tang_Recurrent_Mask_Refinement_for_Few-Shot_Medical_Image_Segmentation_ICCV_2021_paper.pdf) |
| 2021 | Big Self-Supervised Models Advance Medical Image Classification | Shekoofeh Azizi, Basil Mustafa, Fiona Ryan, Zachary Beaver, Jan Freyberg, Jonathan Deaton, Aaron Loh, Alan Karthikesalingam, Simon Kornblith, Ting Chen, Vivek Natarajan, Mohammad Norouzi | Self-supervised pretraining followed by supervised fine-tuning has seen success in image recognition, especially when labeled examples are scarce, but has received limited attention in medical image analysis. This paper studies the effectiveness of self-supervised learning as a pretraining strategy for medical image classification. We conduct experiments on two distinct tasks: dermatology condition classification from digital camera images and multi-label chest X-ray classification, and demonstrate that self-supervised learning on ImageNet, followed by additional self-supervised learning on unlabeled domain-specific medical images significantly improves the accuracy of medical image classifiers.We introduce a novel Multi-Instance Contrastive Learning (MICLe) method that uses multiple images of the underlying pathology per patient case, when available, to construct more informative positive pairs for self-supervised learning. Combining our contributions, we achieve an improvement of 6.7% in top-1 accuracy and an improvement of 1.1% in mean AUC on dermatology and chest X-ray classification respectively, outperforming strong supervised baselines pretrained on ImageNet. In addition, we show that big self-supervised models are robust to distribution shift and can learn efficiently with a small number of labeled medical images. | 自监督预训练后跟监督微调在图像识别中取得了成功，特别是在标记示例稀缺的情况下，但在医学图像分析中受到了有限的关注。本文研究了自监督学习作为医学图像分类预训练策略的有效性。我们在两个不同的任务上进行实验：从数码相机图像中进行皮肤病分类和多标记胸部X光分类，并证明在ImageNet上进行自监督学习，然后在未标记的特定领域医学图像上进行额外的自监督学习显著提高了医学图像分类器的准确性。我们引入了一种新颖的多实例对比学习（MICLe）方法，利用患者病理学的多个图像（如果可用）来构建更具信息性的正对自监督学习的对。结合我们的贡献，我们在皮肤病和胸部X光分类中分别实现了1个顶部准确度6.7％的改进和1.1％平均AUC的改进，优于在ImageNet上预训练的强监督基线。此外，我们表明大型自监督模型对分布转移具有鲁棒性，并且可以在少量标记的医学图像上高效学习。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Azizi_Big_Self-Supervised_Models_Advance_Medical_Image_Classification_ICCV_2021_paper.pdf) |
| 2021 | T-AutoML: Automated Machine Learning for Lesion Segmentation Using Transformers in 3D Medical Imaging | Dong Yang, Andriy Myronenko, Xiaosong Wang, Ziyue Xu, Holger R. Roth, Daguang Xu | Lesion segmentation in medical imaging has been an important topic in clinical research. Researchers have proposed various detection and segmentation algorithms to address this task. Recently, deep learning-based approaches have significantly improved the performance over conventional methods. However, most state-of-the-art deep learning methods require the manual design of multiple network components and training strategies. In this paper, we propose a new automated machine learning algorithm, T-AutoML, which not only searches for the best neural architecture, but also finds the best combination of hyper-parameters and data augmentation strategies simultaneously. The proposed method utilizes the modern transformer model, which is introduced to adapt to the dynamic length of the search space embedding and can significantly improve the ability of the search. We validate T-AutoML on several large-scale public lesion segmentation data-sets and achieve state-of-the-art performance. | 在医学图像中的病变分割一直是临床研究中的重要课题。研究人员已经提出各种检测和分割算法来解决这个任务。最近，基于深度学习的方法显著提高了与传统方法相比的性能。然而，大多数最先进的深度学习方法需要手动设计多个网络组件和训练策略。在本文中，我们提出了一种新的自动机器学习算法T-AutoML，该算法不仅搜索最佳神经结构，还同时找到最佳的超参数组合和数据增强策略。所提出的方法利用了现代变换器模型，该模型被引入以适应搜索空间嵌入的动态长度，并且可以显著提高搜索能力。我们在几个大规模公共病变分割数据集上验证了T-AutoML，并取得了最先进的性能。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_T-AutoML_Automated_Machine_Learning_for_Lesion_Segmentation_Using_Transformers_in_ICCV_2021_paper.pdf) |
| 2021 | Preservational Learning Improves Self-Supervised Medical Image Models by Reconstructing Diverse Contexts | Hong-Yu Zhou, Chixiang Lu, Sibei Yang, Xiaoguang Han, Yizhou Yu | Preserving maximal information is the basic principle of designing self-supervised learning methodologies. To reach this goal, contrastive learning adopts an implicit way which is contrasting image pairs. However, we believe it is not fully optimal to simply use the contrastive estimation for preservation. Moreover, it is necessary and complemental to introduce an explicit solution to preserve more information. From this perspective, we introduce Preservational Learning to reconstruct diverse image contexts in order to preserve more information in learned representations. Together with the contrastive loss, we present Preservational Contrastive Representation Learning (PCRL) for learning self-supervised medical representations. PCRL provides very competitive results under the pretraining-finetuning protocol, outperforming both self-supervised and supervised counterparts in 5 classification/segmentation tasks substantially. | 保留最大信息量是设计自监督学习方法的基本原则。为了实现这一目标，对比学习采用了一种隐式方式，即对比图像对。然而，我们认为简单地使用对比估计来保留信息并不是完全最优的。此外，引入一种显式解决方案来保留更多信息是必要且补充的。从这个角度出发，我们引入了保留式学习，以重建多样的图像背景，以保留学习表示中的更多信息。结合对比损失，我们提出了用于学习自监督医学表示的保留式对比表示学习（PCRL）。在预训练-微调协议下，PCRL在5个分类/分割任务中表现出色，明显优于自监督和监督对照方法。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Preservational_Learning_Improves_Self-Supervised_Medical_Image_Models_by_Reconstructing_Diverse_ICCV_2021_paper.pdf) |
| 2021 | Joint Topology-Preserving and Feature-Refinement Network for Curvilinear Structure Segmentation | Mingfei Cheng, Kaili Zhao, Xuhong Guo, Yajing Xu, Jun Guo | Curvilinear structure segmentation (CSS) is under semantic segmentation, whose applications include crack detection, aerial road extraction, and biomedical image segmentation. In general, geometric topology and pixel-wise features are two critical aspects of CSS. However, most semantic segmentation methods only focus on enhancing feature representations while existing CSS techniques emphasize preserving topology alone. In this paper, we present a Joint Topology-preserving and Feature-refinement Network (JTFN) that jointly models global topology and refined features based on an iterative feedback learning strategy. Specifically, we explore the structure of objects to help preserve corresponding topologies of predicted masks, thus design a reciprocative two-stream module for CSS and boundary detection. In addition, we introduce such topology-aware predictions as feedback guidance that refines attentive features by supplementing and enhancing saliencies. To the best of our knowledge, this is the first work that jointly addresses topology preserving and feature refinement for CSS. We evaluate JTFN on four datasets of diverse applications: Crack500, CrackTree200, Roads, and DRIVE. Results show that JTFN performs best in comparison with alternative methods. Code is available. | 曲线结构分割（CSS）属于语义分割的范畴，其应用包括裂纹检测、航空道路提取和生物医学图像分割。一般来说，几何拓扑和像素特征是CSS的两个关键方面。然而，大多数语义分割方法只注重增强特征表示，而现有的CSS技术则侧重于保持拓扑结构。本文提出了一种联合拓扑保持和特征细化网络（JTFN），该网络基于迭代反馈学习策略，共同建模全局拓扑和精细特征。具体而言，我们探索对象的结构，以帮助保持预测掩模的相应拓扑结构，因此设计了一个相互作用的双流模块用于CSS和边界检测。此外，我们引入了拓扑感知预测作为反馈指导，通过补充和增强显著性来细化关注特征。据我们所知，这是首个联合处理CSS拓扑保持和特征细化的工作。我们在四个具有多样化应用的数据集上评估了JTFN：Crack500、CrackTree200、Roads和DRIVE。结果显示，与替代方法相比，JTFN表现最佳。代码已提供。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Cheng_Joint_Topology-Preserving_and_Feature-Refinement_Network_for_Curvilinear_Structure_Segmentation_ICCV_2021_paper.pdf) |
| 2021 | Self-Supervised Vessel Segmentation via Adversarial Learning | Yuxin Ma, Yang Hua, Hanming Deng, Tao Song, Hao Wang, Zhengui Xue, Heng Cao, Ruhui Ma, Haibing Guan | Vessel segmentation is critically essential for diagnosinga series of diseases, e.g., coronary artery disease and retinal disease. However, annotating vessel segmentation maps of medical images is notoriously challenging due to the tiny and complex vessel structures, leading to insufficient available annotated datasets for existing supervised methods and domain adaptation methods. The subtle structures and confusing background of medical images further suppress the efficacy of unsupervised methods. In this paper, we propose a self-supervised vessel segmentation method via adversarial learning. Our method learns vessel representations by training an attention-guided generator and a segmentation generator to simultaneously synthesize fake vessels and segment vessels out of coronary angiograms. To support the research, we also build the first X-ray angiography coronary vessel segmentation dataset, named XCAD. We evaluate our method extensively on multiple vessel segmentation datasets, including the XCAD dataset, the DRIVE dataset,and the STARE dataset. The experimental results show our method suppresses unsupervised methods significantly and achieves competitive performance compared with supervised methods and traditional methods. | 血管分割对于诊断一系列疾病，如冠状动脉疾病和视网膜疾病至关重要。然而，由于血管结构细小复杂，标注医学图像的血管分割地图极具挑战性，导致现有监督方法和领域适应方法缺乏可用的标注数据集。医学图像的微小结构和混乱背景进一步抑制了无监督方法的有效性。本文提出了一种通过对抗学习实现的自监督血管分割方法。我们的方法通过训练引导注意力的生成器和分割生成器同时合成假血管并从冠状动脉造影图像中分割血管来学习血管表示。为了支持研究，我们还建立了第一个X射线血管造影冠状血管分割数据集，命名为XCAD。我们在多个血管分割数据集上广泛评估了我们的方法，包括XCAD数据集、DRIVE数据集和STARE数据集。实验结果表明，我们的方法显著抑制了无监督方法，并与监督方法和传统方法相比取得了竞争性能。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Ma_Self-Supervised_Vessel_Segmentation_via_Adversarial_Learning_ICCV_2021_paper.pdf) |
| 2021 | GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-Efficient Medical Image Recognition | Shih-Cheng Huang, Liyue Shen, Matthew P. Lungren, Serena Yeung | In recent years, the growing number of medical imaging studies is placing an ever-increasing burden on radiologists. Deep learning provides a promising solution for automatic medical image analysis and clinical decision support. However, large-scale manually labeled datasets required for training deep neural networks are difficult and expensive to obtain for medical images. The purpose of this work is to develop label-efficient multimodal medical imaging representations by leveraging radiology reports. Specifically, we propose an attention-based framework (GLoRIA) for learning global and local representations by contrasting image sub-regions and words in the paired report. In addition, we propose methods to leverage the learned representations for various downstream medical image recognition tasks with limited labels. Our results demonstrate high-performance and label-efficiency for image-text retrieval, classification (finetuning and zeros-shot settings), and segmentation on different datasets. | 近年来，医学影像研究数量不断增加，给放射科医师带来了越来越大的负担。深度学习为自动医学图像分析和临床决策支持提供了有希望的解决方案。然而，用于训练深度神经网络的大规模手动标记数据集对于医学图像来说很难且昂贵获得。本文旨在通过利用放射学报告开发标签高效的多模态医学影像表示。具体来说，我们提出了一种基于注意力的框架（GLoRIA），通过对比成对报告中的图像子区域和单词来学习全局和局部表示。此外，我们提出了利用学习到的表示来处理各种下游医学图像识别任务的方法，这些任务受限于标签数量。我们的结果表明，在不同数据集上进行图像文本检索、分类（微调和零样本设置）和分割时，具有高性能和标签效率。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_GLoRIA_A_Multimodal_Global-Local_Representation_Learning_Framework_for_Label-Efficient_Medical_ICCV_2021_paper.pdf) |
| 2021 | FFT-OT: A Fast Algorithm for Optimal Transportation | Na Lei, Xianfeng Gu | An optimal transportation map finds the most economical way to transport one probability measure to the other. It has been applied in a broad range of applications in vision, deep learning and medical images. By Brenier theory, computing the optimal transport map is equivalent to solving a Monge-Ampere equation. Due to the highly non-linear nature, the computation of optimal transportation maps in large scale is very challenging.  This work proposes a simple but powerful method, the FFT-OT algorithm, to tackle this difficulty based on three key ideas. First, solving Monge-Ampere equation is converted to a fixed point problem; Second, the obliqueness property of optimal transportation maps are reformulated as Neumann boundary conditions on rectangular domains; Third, FFT is applied in each iteration to solve a Poisson equation in order to improve the efficiency.  Experiments on surfaces captured from 3D scanning and reconstructed from medical imaging are conducted, and compared with other existing methods. Our experimental results show that the proposed FFT-OT algorithm is simple, general and scalable with high efficiency and accuracy. | 一种最优运输图找到了将一个概率度量传输到另一个度量的最经济方式。它已经应用于视觉、深度学习和医学图像等广泛领域。根据Brenier理论，计算最优运输图等同于解决蒙日-安培方程。由于其高度非线性特性，大规模计算最优运输图非常具有挑战性。本研究提出了一种简单但强大的方法，即FFT-OT算法，以应对这一困难，基于三个关键思想。首先，将解决蒙日-安培方程转化为一个固定点问题；其次，将最优运输图的倾斜性质重新表述为矩形域上的诺伊曼边界条件；第三，每次迭代中应用FFT来解决泊松方程以提高效率。对从3D扫描捕获的表面和从医学成像重建的表面进行实验，并与其他现有方法进行比较。我们的实验结果表明，所提出的FFT-OT算法简单、通用、可扩展，具有高效率和准确性。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Lei_FFT-OT_A_Fast_Algorithm_for_Optimal_Transportation_ICCV_2021_paper.pdf) |
| 2021 | Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation | Xiaofeng Liu, Site Li, Yubin Ge, Pengyi Ye, Jane You, Jun Lu | The unsupervised domain adaptation (UDA) has been widely adopted to alleviate the data scalability issue, while the existing works usually focus on classifying independently discrete labels. However, in many tasks (e.g., medical diagnosis), the labels are discrete and successively distributed. The UDA for ordinal classification requires inducing non-trivial ordinal distribution prior to the latent space. Target for this, the partially ordered set (poset) is defined for constraining the latent vector. Instead of the typically i.i.d. Gaussian latent prior, in this work, a recursively conditional Gaussian (RCG) set is adapted for ordered constraint modeling, which admits a tractable joint distribution prior. Furthermore, we are able to control the density of content vector that violates the poset constraints by a simple "three-sigma rule". We explicitly disentangle the cross-domain images into a shared ordinal prior induced ordinal content space and two separate source/target ordinal-unrelated spaces, and the self-training is worked on the shared space exclusively for ordinal-aware domain alignment. Extensive experiments on UDA medical diagnoses and facial age estimation demonstrate its effectiveness. | 无监督领域自适应（UDA）被广泛采用以缓解数据可扩展性问题，然而现有研究通常集中于独立离散标签的分类。然而，在许多任务中（例如医学诊断），标签是离散且连续分布的。用于序数分类的UDA需要在潜在空间中引入非平凡的序数分布先验。为此，定义了部分有序集合（poset）以约束潜在向量。在这项工作中，不再使用典型的独立同分布高斯潜在先验，而是为有序约束建模采用递归条件高斯（RCG）集合，这允许可追溯的联合分布先验。此外，我们能够通过简单的“三西格玛规则”来控制违反poset约束的内容向量的密度。我们明确地将跨领域图像解开为一个共享的序数先验诱导的序数内容空间和两个独立的源/目标序数无关空间，并且自训练仅在共享空间中进行，用于序数感知的域对齐。对UDA医学诊断和面部年龄估计的广泛实验证明了其有效性。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Recursively_Conditional_Gaussian_for_Ordinal_Unsupervised_Domain_Adaptation_ICCV_2021_paper.pdf) |
| 2021 | Dynamic CT Reconstruction From Limited Views With Implicit Neural Representations and Parametric Motion Fields | Albert W. Reed, Hyojin Kim, Rushil Anirudh, K. Aditya Mohan, Kyle Champley, Jingu Kang, Suren Jayasuriya | Reconstructing dynamic, time-varying scenes with computed tomography (4D-CT) is a challenging and ill-posed problem common to industrial and medical settings. Existing 4D-CT reconstructions are designed for sparse sampling schemes that require fast CT scanners to capture multiple, rapid revolutions around the scene in order to generate high quality results. However, if the scene is moving too fast, then the sampling occurs along a limited view and is difficult to reconstruct due to spatiotemporal ambiguities. In this work, we design a reconstruction pipeline using implicit neural representations coupled with a novel parametric motion field warping to perform limited view 4D-CT reconstruction of rapidly deforming scenes. Importantly, we utilize a differentiable analysis-by-synthesis approach to compare with captured x-ray sinogram data in a self-supervised fashion. Thus, our resulting optimization method requires no training data to reconstruct the scene. We demonstrate that our proposed system robustly reconstructs scenes containing deformable and periodic motion and validate against state-of-the-art baselines. Further, we demonstrate an ability to reconstruct continuous spatiotemporal representations of our scenes and upsample them to arbitrary volumes and frame rates post-optimization. This research opens a new avenue for implicit neural representations in computed tomography reconstruction in general. Code is available at https://github.com/awreed/DynamicCTReconstruction. | 用计算机断层扫描（4D-CT）重建动态、时变场景是工业和医学领域共同面临的具有挑战性和不适定性的问题。现有的4D-CT重建设计用于稀疏采样方案，需要快速CT扫描仪在场景周围进行多次快速旋转，以生成高质量的结果。然而，如果场景移动过快，那么采样只能在有限的视图中进行，由于时空模糊而难以重建。在这项工作中，我们设计了一个重建流程，使用隐式神经表示结合新颖的参数化运动场变形，执行快速变形场景的有限视图4D-CT重建。重要的是，我们利用可微分的分析合成方法以自监督的方式与捕获的X射线正弦图数据进行比较。因此，我们的优化方法无需训练数据即可重建场景。我们证明我们提出的系统能够稳健地重建包含可变形和周期性运动的场景，并验证了与最先进基线的比较。此外，我们展示了在优化后能够重建我们场景的连续时空表示，并将其上采样到任意体积和帧速率。这项研究为计算机断层扫描重建中的隐式神经表示开辟了一条新途径。代码可在https://github.com/awreed/DynamicCTReconstruction找到。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Reed_Dynamic_CT_Reconstruction_From_Limited_Views_With_Implicit_Neural_Representations_ICCV_2021_paper.pdf) |
| 2021 | Visual-Textual Attentive Semantic Consistency for Medical Report Generation | Yi Zhou, Lei Huang, Tao Zhou, Huazhu Fu, Ling Shao | Diagnosing diseases from medical radiographs and writing reports requires professional knowledge and is time-consuming. To address this, automatic medical report generation approaches have recently gained interest. However, identifying diseases as well as correctly predicting their corresponding sizes, locations and other medical description patterns, which is essential for generating high-quality reports, is challenging. Although previous methods focused on producing readable reports, how to accurately detect and describe findings that match with the query X-Ray has not been successfully addressed. In this paper, we propose a multi-modality semantic attention model to integrate visual features, predicted key finding embeddings, as well as clinical features, and progressively decode reports with visual-textual semantic consistency. First, multi-modality features are extracted and attended with the hidden states from the sentence decoder, to encode enriched context vectors for better decoding a report. These modalities include regional visual features of scans, semantic word embeddings of the top-K findings predicted with high probabilities, and clinical features of indications. Second, the progressive report decoder consists of a sentence decoder and a word decoder, where we propose image-sentence matching and description accuracy losses to constrain the visual-textual semantic consistency. Extensive experiments on the public MIMIC-CXR and IU X-Ray datasets show that our model achieves consistent improvements over the state-of-the-art methods. | 从医学放射照片诊断疾病并撰写报告需要专业知识并且耗时耗力。为了解决这一问题，自动生成医学报告的方法近年来备受关注。然而，识别疾病以及准确预测其对应的大小、位置和其他医学描述模式，这对生成高质量报告至关重要，却是具有挑战性的。虽然先前的方法侧重于生成可读的报告，但如何准确检测和描述与查询X射线相匹配的发现尚未成功解决。在本文中，我们提出了一种多模态语义关注模型，将视觉特征、预测的关键发现嵌入以及临床特征整合起来，并逐步解码具有视觉-文本语义一致性的报告。首先，提取多模态特征并与句子解码器的隐藏状态进行关注，以编码丰富的上下文向量以更好地解码报告。这些模态包括扫描的区域视觉特征，通过高概率预测的前K个发现的语义词嵌入，以及指标的临床特征。其次，逐步报告解码器包括句子解码器和单词解码器，我们提出图像-句子匹配和描述准确性损失来限制视觉-文本语义一致性。在公共MIMIC-CXR和IU X射线数据集上进行的大量实验证明，我们的模型在现有方法上取得了一致的改进。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Visual-Textual_Attentive_Semantic_Consistency_for_Medical_Report_Generation_ICCV_2021_paper.pdf) |
| 2021 | BioFors: A Large Biomedical Image Forensics Dataset | Ekraam Sabir, Soumyaroop Nandi, Wael Abd-Almageed, Prem Natarajan | Research in media forensics has gained traction to combat the spread of misinformation. However, most of this research has been directed towards content generated on social media. Biomedical image forensics is a related problem, where manipulation or misuse of images reported in biomedical research documents is of serious concern. The problem has failed to gain momentum beyond an academic discussion due to an absence of benchmark datasets and standardized tasks. In this paper we present BioFors -- the first dataset for benchmarking common biomedical image manipulations. BioFors comprises 47,805 images extracted from 1,031 open-source research papers. Images in BioFors are divided into four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also propose three tasks for forensic analysis -- external duplication detection, internal duplication detection and cut/sharp-transition detection. We benchmark BioFors on all tasks with suitable state-of-the-art algorithms. Our results and analysis show that existing algorithms developed on common computer vision datasets are not robust when applied to biomedical images, validating that more research is required to address the unique challenges of biomedical image forensics. | 媒体取证研究已经开始引起关注，以打击虚假信息的传播。然而，大多数研究都集中在社交媒体上生成的内容上。生物医学图像取证是一个相关的问题，其中对生物医学研究文件中报道的图像进行篡改或滥用是一个严重问题。由于缺乏基准数据集和标准化任务，这个问题尚未在学术讨论之外引起关注。在本文中，我们提出了BioFors -- 用于基准测试常见生物医学图像篡改的第一个数据集。BioFors包括从1,031篇开源研究论文中提取的47,805张图像。BioFors中的图像分为四类--显微镜、蛋白印迹/凝胶、FACS和宏观镜检。我们还提出了三项取证分析任务--外部复制检测、内部复制检测和切割/锐变检测。我们使用适当的最先进算法在所有任务上对BioFors进行基准测试。我们的结果和分析表明，现有的在常见计算机视觉数据集上开发的算法在应用于生物医学图像时并不稳健，验证了需要进一步研究来解决生物医学图像取证的独特挑战。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Sabir_BioFors_A_Large_Biomedical_Image_Forensics_Dataset_ICCV_2021_paper.pdf) |
| 2021 | CCT-Net: Category-Invariant Cross-Domain Transfer for Medical Single-to-Multiple Disease Diagnosis | Yi Zhou, Lei Huang, Tao Zhou, Ling Shao | A medical imaging model is usually explored for the diagnosis of a single disease. However, with the expanding demand for multi-disease diagnosis in clinical applications, multi-function solutions need to be investigated. Previous works proposed to either exploit different disease labels to conduct transfer learning through fine-tuning, or transfer knowledge across different domains with similar diseases. However, these methods still cannot address the real clinical challenge - a multi-disease model is required but annotations for each disease are not always available. In this paper, we introduce the task of transferring knowledge from single-disease diagnosis (source domain) to enhance multi-disease diagnosis (target domain). A category-invariant cross-domain transfer (CCT) method is proposed to address this single-to-multiple extension. First, for domain-specific task learning, we present a confidence weighted pooling (CWP) to obtain coarse heatmaps for different disease categories. Then, conditioned on these heatmaps, category-invariant feature refinement (CIFR) blocks are proposed to better localize discriminative semantic regions related to the corresponding diseases. The category-invariant characteristic enables transferability from the source domain to the target domain. We validate our method in two popular areas: extending diabetic retinopathy to identifying multiple ocular diseases, and extending glioma identification to the diagnosis of other brain tumors. | 医学影像模型通常用于单一疾病的诊断。然而，随着临床应用中对多病种诊断需求的不断扩大，需要研究多功能解决方案。先前的研究提出要么利用不同的疾病标签通过微调进行迁移学习，要么在相似疾病的不同领域之间传递知识。然而，这些方法仍无法解决真正的临床挑战 - 需要一个多病种模型，但并非总是可用每种疾病的注释。在本文中，我们介绍了从单一疾病诊断（源域）转移知识以增强多病种诊断（目标域）的任务。提出了一种类别不变的跨领域转移（CCT）方法来解决这种单一到多个的扩展。首先，为了进行特定于域的任务学习，我们提出了一种置信加权池化（CWP）方法，以获得不同疾病类别的粗略热图。然后，基于这些热图，我们提出了类别不变特征细化（CIFR）块，以更好地定位与相应疾病相关的具有区别性语义区域。类别不变特征使得能够从源域转移到目标域。我们在两个流行领域验证了我们的方法：将糖尿病视网膜病变扩展到识别多种眼部疾病，以及将胶质瘤识别扩展到其他脑肿瘤的诊断。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_CCT-Net_Category-Invariant_Cross-Domain_Transfer_for_Medical_Single-to-Multiple_Disease_Diagnosis_ICCV_2021_paper.pdf) |
| 2021 | Ensemble Attention Distillation for Privacy-Preserving Federated Learning | Xuan Gong, Abhishek Sharma, Srikrishna Karanam, Ziyan Wu, Terrence Chen, David Doermann, Arun Innanje | We consider the problem of Federated Learning (FL) where numerous decentralized computational nodes collaborate with each other to train a centralized machine learning model without explicitly sharing their local data samples. Such decentralized training naturally leads to issues of imbalanced or differing data distributions among the local models and challenges in fusing them into a central model. Existing FL methods deal with these issues by either sharing local parameters or fusing models via online distillation. However, such a design leads to multiple rounds of inter-node communication resulting in substantial bandwidth consumption, while also increasing the risk of data leakage and consequent privacy issues. To address these problems, we propose a new distillation-based FL framework that can preserve privacy by design, while also consuming substantially less network communication resources when compared to the current state-of-the-art. Our framework engages in inter-node communication using only publicly available and approved datasets, thereby giving explicit privacy control to the user. To distill knowledge among the various local models, our framework involves a novel ensemble distillation algorithm that uses both final prediction as well as model attention. This algorithm explicitly considers the diversity among various local nodes while also seeking consensus among them. This results in a comprehensive technique to distill knowledge from various decentralized nodes. We demonstrate the various aspects and the associated benefits of our FL framework through extensive experiments that produce state-of-the-art results on both classification and segmentation tasks on natural and medical images. | 我们考虑了联邦学习（FL）的问题，许多分散的计算节点相互合作，训练一个集中的机器学习模型，而不需要显式共享他们的本地数据样本。这种分散训练自然导致了本地模型之间数据分布不平衡或不同的问题，以及将它们融合到中央模型中的挑战。现有的FL方法通过共享本地参数或通过在线蒸馏来融合模型来解决这些问题。然而，这样的设计导致多轮节点间通信，导致大量带宽消耗，同时增加了数据泄露和隐私问题的风险。为了解决这些问题，我们提出了一种新的基于蒸馏的FL框架，可以通过设计保护隐私，同时与当前最先进技术相比，消耗相对较少的网络通信资源。我们的框架只使用公开可用和经过批准的数据集进行节点间通信，从而为用户提供明确的隐私控制。为了在各种本地模型之间蒸馏知识，我们的框架涉及一种新颖的集成蒸馏算法，同时使用最终预测和模型注意力。该算法明确考虑了各种本地节点之间的差异，同时寻求它们之间的共识。这导致了一个全面的技术，可以从各个分散节点中蒸馏知识。通过广泛的实验，我们展示了我们的FL框架的各个方面及相关好处，该框架在自然和医学图像的分类和分割任务上取得了最先进的结果。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Gong_Ensemble_Attention_Distillation_for_Privacy-Preserving_Federated_Learning_ICCV_2021_paper.pdf) |
| 2021 | Membership Inference Attacks Are Easier on Difficult Problems | Avital Shafran, Shmuel Peleg, Yedid Hoshen | Membership inference attacks (MIA) try to detect if data samples were used to train a neural network model, e.g. to detect copyright abuses. We show that models with higher dimensional input and output are more vulnerable to MIA, and address in more detail models for image translation and semantic segmentation, including medical image segmentation. We show that reconstruction-errors can lead to very effective MIA attacks as they are indicative of memorization. Unfortunately, reconstruction error alone is less effective at discriminating between non-predictable images used in training and easy to predict images that were never seen before. To overcome this, we propose using a novel predictability error that can be computed for each sample, and its computation does not require a training set. Our membership error, obtained by subtracting the predictability error from the reconstruction error, is shown to achieve high MIA accuracy on an extensive number of benchmarks. | 会员推理攻击（MIA）试图检测数据样本是否被用于训练神经网络模型，例如用于检测版权侵权行为。我们展示了具有更高维输入和输出的模型更容易受到MIA攻击，并更详细地讨论了图像翻译和语义分割等模型，包括医学图像分割。我们表明，重建错误可能会导致非常有效的MIA攻击，因为它们表明了记忆。不幸的是，仅有重建错误在区分用于训练的不可预测图像和从未见过的易于预测图像方面的效果较差。为了克服这一问题，我们提出使用一种新颖的可预测性错误，该错误可以针对每个样本进行计算，并且其计算不需要训练集。我们的会员错误，通过从可预测性错误中减去重建错误而获得，被证明在大量基准测试中实现了高MIA准确性。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Shafran_Membership_Inference_Attacks_Are_Easier_on_Difficult_Problems_ICCV_2021_paper.pdf) |
| 2021 | Cherry-Picking Gradients: Learning Low-Rank Embeddings of Visual Data via Differentiable Cross-Approximation | Mikhail Usvyatsov, Anastasia Makarova, Rafael Ballester-Ripoll, Maxim Rakhuba, Andreas Krause, Konrad Schindler | We propose an end-to-end trainable framework that processes large-scale visual data tensors by looking at a fraction of their entries only. Our method combines a neural network encoder with a tensor train decomposition to learn a low-rank latent encoding, coupled with cross-approximation (CA) to learn the representation through a subset of the original samples. CA is an adaptive sampling algorithm that is native to tensor decompositions and avoids working with the full high-resolution data explicitly. Instead, it actively selects local representative samples that we fetch out-of-core and on demand. The required number of samples grows only logarithmically with the size of the input. Our implicit representation of the tensor in the network enables processing large grids that could not be otherwise tractable in their uncompressed form. The proposed approach is particularly useful for large-scale multidimensional grid data (e.g., 3D tomography), and for tasks that require context over a large receptive field (e.g., predicting the medical condition of entire organs). The code is available at https://github.com/aelphy/c-pic. | 我们提出了一个端到端可训练的框架，通过仅查看其部分条目来处理大规模的视觉数据张量。我们的方法将神经网络编码器与张量分解结合起来，学习低秩潜在编码，同时结合交叉逼近（CA）通过原始样本的子集来学习表示。CA是一种适用于张量分解的自适应抽样算法，避免明确处理完整的高分辨率数据。相反，它积极选择本地代表性样本，我们按需从外部核心获取。所需样本数量仅随输入大小对数增长。我们在网络中对张量的隐式表示使得处理大规模网格成为可能，否则这些网格在未压缩形式下是难以处理的。所提出的方法特别适用于大规模多维网格数据（例如，3D断层扫描），以及需要覆盖大范围接受域的任务（例如，预测整个器官的医学状况）。代码可在https://github.com/aelphy/c-pic找到。 | [link](https://openaccess.thecvf.com/content/ICCV2021/papers/Usvyatsov_Cherry-Picking_Gradients_Learning_Low-Rank_Embeddings_of_Visual_Data_via_Differentiable_ICCV_2021_paper.pdf) |
