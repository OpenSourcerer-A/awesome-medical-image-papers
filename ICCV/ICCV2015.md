| 年份 | 题目 | 作者 | 摘要 | 中文摘要 | link |
| --- | --- | --- | --- | --- | --- |
| 2015 | Interpolation on the Manifold of K Component GMMs | Hyunwoo J. Kim, Nagesh Adluru, Monami Banerjee, Baba C. Vemuri, Vikas Singh | Probability density functions (PDFs) are fundamental "objects" in mathematics with numerous applications in computer vision, machine learning and medical imaging. The feasibility of basic operations such as computing the distance between two PDFs and estimating a mean of a set of PDFs is a direct function of the representation we choose to work with. In this paper, we study the Gaussian mixture model  (GMM) representation of the PDFs motivated by its numerous attractive features. (1) GMMs are arguably more interpretable than, say, square root parameterizations (2) the model complexity can be explicitly controlled by the number of components and (3) they are already widely used in many applications. The main contributions of  this paper are numerical algorithms to enable basic operations on such objects that strictly respect their underlying geometry.  For instance, when operating with a set of k component GMMs,  a first order expectation is that the result of  simple operations like interpolation and averaging should  provide an object that is also a k component GMM.  The literature provides very little guidance on enforcing such  requirements systematically. It turns out that these tasks are  important internal modules for analysis and processing of a field of ensemble average propagators (EAPs), common  in diffusion weighted magnetic resonance imaging. We provide proof of principle experiments showing how the proposed algorithms for interpolation can facilitate statistical  analysis of such data, essential to many neuroimaging studies. Separately, we also derive interesting connections of our algorithm  with functional spaces of Gaussians, that may be of independent interest. | 概率密度函数（PDFs）是数学中的基本“对象”，在计算机视觉、机器学习和医学成像等领域有着广泛的应用。基本操作的可行性，如计算两个PDF之间的距离和估计一组PDF的均值，直接取决于我们选择的表示方式。本文研究了由其众多吸引人的特性激发的PDF的高斯混合模型（GMM）表示。 （1）GMM可以说比平方根参数化更具解释性（2）模型复杂性可以通过成分数量明确控制（3）它们已经广泛应用于许多领域。本文的主要贡献是提出了数值算法，使得对这些对象进行基本操作时严格遵守它们的基础几何结构。例如，当操作一组k个成分的GMM时，一个首要期望是，简单操作如插值和平均值的结果也应该是一个k个成分的GMM。文献中很少提供如何系统地实现这些要求的指导。事实证明，这些任务对于分析和处理扩散加权磁共振成像中常见的集合平均传播子（EAPs）领域非常重要。我们提供了原理实验，展示了插值算法如何有助于这些数据的统计分析，对许多神经影像学研究至关重要。此外，我们还推导出我们的算法与高斯函数空间的有趣联系，这可能会引起独立的兴趣。 | [link](https://openaccess.thecvf.com/content_iccv_2015/papers/Kim_Interpolation_on_the_ICCV_2015_paper.pdf) |
| 2015 | Learning to Boost Filamentary Structure Segmentation | Lin Gu, Li Cheng | The challenging problem of filamentary structure segmentation has a broad range of applications in biological and medical fields. A critical yet challenging issue remains on how to detect and restore the small filamentary fragments from backgrounds: The small fragments are of diverse shapes and appearances, meanwhile the backgrounds could be cluttered and ambiguous. Focusing on this issue, this paper proposes an iterative two-step learning-based approach to boost the performance based on a base segmenter arbitrarily chosen from a number of existing segmenters: We start with an initial partial segmentation where the filamentary structure obtained is of high confidence based on this existing segmenter. We also define a scanning horizon as epsilon balls centred around the partial segmentation result. Step one of our approach centers on a data-driven latent classification tree model to detect the filamentary fragments. This model is learned via a training process, where a large number of distinct local figure/background separation scenarios are established and geometrically organized into a tree structure. Step two spatially restores the isolated fragments back to the current partial segmentation, which is accomplished by means of completion fields and matting. Both steps are then alternated with the growth of partial segmentation result, until the input image space is entirely explored. Our approach is rather generic and can be easily augmented to a wide range of existing supervised/unsupervised segmenters to produce an improved result. This has been empirically verified on specific filamentary structure segmentation tasks: retinal blood vessel segmentation as well as neuronal segmentations, where noticeable improvement has been shown over the original state-of-the-arts. | 纤维结构分割这一挑战性问题在生物医学领域有着广泛的应用。然而，一个至关重要且具有挑战性的问题是如何检测和恢复背景中的小片状纤维：这些小片状纤维具有多样的形状和外观，同时背景可能混乱模糊。针对这一问题，本文提出了一种迭代的两步学习方法，以提高基于已有分割器任意选择的基础分割器的性能：我们从一个初始的部分分割开始，其中所得到的纤维结构基于这个现有分割器的置信度较高。我们还定义了一个扫描范围，即围绕部分分割结果的ε球。我们方法的第一步侧重于基于数据驱动的潜在分类树模型来检测纤维片状。这个模型是通过一个训练过程学习的，其中建立了大量不同的局部图像/背景分离场景，并在几何上组织成树结构。第二步将孤立的片状重新放回到当前部分分割中，这通过完整性场和抠图完成。两个步骤随着部分分割结果的增长交替进行，直到完全探索输入图像空间。我们的方法相当通用，可以轻松扩展到各种现有的监督/无监督分割器，以产生改进的结果。这已在特定的纤维结构分割任务上经过经验验证：视网膜血管分割以及神经元分割，显示出明显的改进超过原始的最先进技术。 | [link](https://openaccess.thecvf.com/content_iccv_2015/papers/Gu_Learning_to_Boost_ICCV_2015_paper.pdf) |
| 2015 | Unsupervised Cross-Modal Synthesis of Subject-Specific Scans | Raviteja Vemulapalli, Hien Van Nguyen, Shaohua Kevin Zhou | Recently, cross-modal synthesis of subject-specific scans has been receiving significant attention from the medical imaging community. Though various synthesis approaches have been introduced in the recent past, most of them are either tailored to a specific application or proposed for the supervised setting, i.e., they assume the availability of training data from the same set of subjects in both source and target modalities. But, collecting multiple scans from each subject is undesirable. Hence, to address this issue, we propose a general unsupervised cross-modal medical image synthesis approach that works without paired training data. Given a source modality image of a subject, we first generate multiple target modality candidate values for each voxel independently using cross-modal nearest neighbor search. Then, we select the best candidate values jointly for all the voxels by simultaneously maximizing a global mutual information cost function and a local spatial consistency cost function. Finally, we use coupled sparse representation for further refinement of synthesized images. Our experiments on generating T1-MRI brain scans from T2-MRI and vice versa demonstrate that the synthesis capability of the proposed unsupervised approach is comparable to various state-of-the-art supervised approaches in the literature. | 最近，针对特定主题扫描的跨模态合成在医学影像领域引起了广泛关注。虽然最近引入了各种合成方法，但大多数要么专门针对特定应用，要么提出了针对受监督设置的方法，即它们假设在源和目标模态中都有来自相同一组受试者的训练数据可用。但是，收集每个受试者的多个扫描是不可取的。因此，为了解决这个问题，我们提出了一种通用的无监督跨模态医学图像合成方法，可以在没有配对训练数据的情况下工作。给定一个主题的源模态图像，我们首先使用跨模态最近邻搜索独立地为每个体素生成多个目标模态候选值。然后，我们通过同时最大化全局互信息成本函数和局部空间一致性成本函数来联合选择所有体素的最佳候选值。最后，我们使用耦合稀疏表示来进一步完善合成图像。我们对从T2-MRI生成T1-MRI脑部扫描及反之的实验表明，所提出的无监督方法的合成能力与文献中各种最先进的受监督方法相当。 | [link](https://openaccess.thecvf.com/content_iccv_2015/papers/Vemulapalli_Unsupervised_Cross-Modal_Synthesis_ICCV_2015_paper.pdf) |
| 2015 | POP Image Fusion - Derivative Domain Image Fusion Without Reintegration | Graham D. Finlayson, Alex E. Hayes | There are many applications where multiple images are fused to form a single summary greyscale or colour output, including computational photography (e.g. RGB-NIR), diffusion tensor imaging (medical), and remote sensing. Often, and intuitively, image fusion is carried out in the derivative domain. Here, a new composite fused derivative is found that best accounts for the detail across all images and then the resulting gradient field is reintegrated. However, the reintegration step generally hallucinates new detail (not appearing in any of the input  image bands) including halo and bending artifacts. In this paper we avoid these hallucinated details by avoiding the reintegration step.  Our work builds directly on the work of Socolinsky and Wolff who derive their equivalent gradient field from the per-pixel Di Zenzo structure tensor which is defined as the inner product of the image Jacobian. We show that the x- and y- derivatives of the projection of the original image onto the Principal characteristic vector of the Outer Product (POP) of the Jacobian generates the same equivalent gradient field. In so doing, we have derived a fused image that has the derivative structure we seek. Of course, this projection will be meaningful only where the Jacobian has non-zero derivatives, so we diffuse the projection directions using a bilateral filter before we calculate the fused image. The resulting POP fused image has maximal fused detail but avoids hallucinated artifacts. Experiments demonstrate our method delivers state of the art image fusion performance.  | 在许多应用中，多个图像被融合成单个摘要灰度或彩色输出，包括计算摄影（例如RGB-NIR）、扩散张量成像（医学）和遥感。通常，直觉上，图像融合是在导数域中进行的。在这里，找到了一个新的复合融合导数，最能解释所有图像的细节，然后重新集成生成的梯度场。然而，重新集成步骤通常会产生新的细节（不出现在任何输入图像波段中），包括光晕和弯曲伪影。在本文中，我们通过避免重新集成步骤来避免这些虚构的细节。我们的工作直接建立在Socolinsky和Wolff的工作基础上，他们从逐像素Di Zenzo结构张量中推导出等效梯度场，该结构张量定义为图像雅可比矩阵的内积。我们展示了原始图像在雅可比矩阵的外积（POP）的主特征向量上的投影的x和y导数生成相同的等效梯度场。这样做，我们推导出一个具有所需导数结构的融合图像。当然，这种投影只有在雅可比矩阵具有非零导数时才有意义，因此我们在计算融合图像之前使用双边滤波器扩散投影方向。结果的POP融合图像具有最大的融合细节，但避免了虚构的伪影。实验证明我们的方法提供了最先进的图像融合性能。 | [link](https://openaccess.thecvf.com/content_iccv_2015/papers/Finlayson_POP_Image_Fusion_ICCV_2015_paper.pdf) |
